{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multi-Turn RL Evaluation\n",
        "\n",
        "Framework for evaluating multi-turn RL rollouts where:\n",
        "- Tasks run for ~50 steps (some terminate early)\n",
        "- Every step is recorded for each rollout\n",
        "- Rewards assigned at the end\n",
        "- Data collected for backprop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "from typing import List, Dict, Union, Optional, Any, Tuple\n",
        "from copy import deepcopy\n",
        "import json\n",
        "import pickle\n",
        "from dataclasses import dataclass, field, asdict\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LLMGenerator:\n",
        "    def __init__(self, model_name: str):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(model_name, dtype=\"auto\", device_map=\"auto\")\n",
        "        if self.tokenizer.pad_token is None:\n",
        "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "        self.tokenizer.padding_side = \"left\"  # decoder-only: left padding\n",
        "        self.think_start_id = 151667  # <think>\n",
        "        self.think_end_id = 151668    # </think>\n",
        "\n",
        "    def generate(self,\n",
        "                 prompts: Union[str, List[str]],\n",
        "                 max_new_tokens: int = 512,\n",
        "                 temperature: float = 0.6,\n",
        "                 num_return_sequences: int = 1,\n",
        "                 enable_thinking: bool = True,\n",
        "                 return_thinking: bool = True,\n",
        "                 **kwargs\n",
        "                 ) -> Union[str, List[str]]:\n",
        "\n",
        "        single_prompt = isinstance(prompts[0], dict)\n",
        "\n",
        "        print(\"single prompt\", single_prompt)\n",
        "\n",
        "        if single_prompt:\n",
        "            prompts = [prompts]\n",
        "\n",
        "        # Apply chat template with thinking enabled/disabled\n",
        "        texts = [\n",
        "            self.tokenizer.apply_chat_template(\n",
        "                prompt,\n",
        "                tokenize=False,\n",
        "                add_generation_prompt=True,\n",
        "                enable_thinking=enable_thinking\n",
        "            )\n",
        "            for prompt in prompts\n",
        "        ]\n",
        "\n",
        "        model_inputs = self.tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\").to(self.model.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model.generate(\n",
        "                **model_inputs,\n",
        "                max_new_tokens=max_new_tokens,\n",
        "                temperature=temperature,\n",
        "                do_sample=temperature > 0,\n",
        "                num_return_sequences=num_return_sequences,\n",
        "                **kwargs\n",
        "            )\n",
        "\n",
        "        results = self._decode_batch(\n",
        "            outputs,\n",
        "            model_inputs.input_ids,\n",
        "            num_return_sequences=num_return_sequences,\n",
        "            return_thinking=return_thinking\n",
        "        )\n",
        "\n",
        "        return results[0] if single_prompt else results\n",
        "\n",
        "    def _decode_batch(self, outputs, input_ids, num_return_sequences, return_thinking):\n",
        "        batch_size = input_ids.shape[0]\n",
        "        prompt_lens = [input_ids[i].shape[0] for i in range(batch_size)]\n",
        "\n",
        "        # Reshape to [batch_size, num_return_sequences, seq_len]\n",
        "        outputs = outputs.view(batch_size, num_return_sequences, -1)\n",
        "\n",
        "        results = []\n",
        "        for batch_idx in range(batch_size):\n",
        "            prompt_len = prompt_lens[batch_idx]\n",
        "            batch_results = []\n",
        "\n",
        "            for seq_idx in range(num_return_sequences):\n",
        "                # Get full generated sequence for this sample\n",
        "                full_seq = outputs[batch_idx, seq_idx]\n",
        "\n",
        "                # Slice off prompt tokens to get model's output only\n",
        "                output_ids = full_seq[prompt_len:].tolist()\n",
        "\n",
        "                if return_thinking:\n",
        "                    thinking, content = self._parse_thinking(output_ids)\n",
        "                    # Return tuple of (thinking, content)\n",
        "                    batch_results.append([thinking, content])\n",
        "                else:\n",
        "                    # Standard: decode everything after prompt\n",
        "                    content = self.tokenizer.decode(\n",
        "                        full_seq[prompt_len:],\n",
        "                        skip_special_tokens=True\n",
        "                    ).strip()\n",
        "                    batch_results.append(content)\n",
        "\n",
        "            # If num_return_sequences=1, unwrap the list\n",
        "            results.append(batch_results[0] if num_return_sequences == 1 else batch_results)\n",
        "\n",
        "        return results\n",
        "\n",
        "    def _parse_thinking(self, output_ids: List[int]) -> Tuple[str, str]:\n",
        "        \"\"\"\n",
        "        Split thinking and content at the </think> token.\n",
        "        Uses reverse index trick to find last occurrence.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Find last </think> token (handles nested <think> tags)\n",
        "            # output_ids[::-1] creates reversed list\n",
        "            # .index() finds first occurrence in reversed = last in original\n",
        "            think_end_idx = len(output_ids) - output_ids[::-1].index(self.think_end_id)\n",
        "\n",
        "            # Include </think> in thinking part\n",
        "            thinking_ids = output_ids[:think_end_idx]\n",
        "            content_ids = output_ids[think_end_idx:]\n",
        "        except ValueError:\n",
        "            # No </think> token found - model skipped thinking\n",
        "            thinking_ids = []\n",
        "            content_ids = output_ids\n",
        "\n",
        "        thinking = self.tokenizer.decode(thinking_ids, skip_special_tokens=True)\n",
        "        content = self.tokenizer.decode(content_ids, skip_special_tokens=True)\n",
        "\n",
        "        return thinking.strip(), content.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_templates(prompts):\n",
        "    \"\"\"Returns an array of prompts. Array of 1 prompt if only one.\"\"\"\n",
        "    gen_p = [{\"role\": \"user\", \"content\": p} for p in prompts]\n",
        "    return gen_p\n",
        "\n",
        "\n",
        "def batch_history(history, prompts):\n",
        "    \"\"\"returns a batch of history + prompts based on the number of prompts\"\"\"\n",
        "    print(len(prompts))\n",
        "    batch = []\n",
        "    templated_prompts = generate_templates(prompts)\n",
        "    for i in range(len(templated_prompts)):\n",
        "        k = deepcopy(history)\n",
        "        k.append(templated_prompts[i])\n",
        "        batch.append(k)\n",
        "    return batch\n",
        "\n",
        "\n",
        "def create_batch(bh, num_gen, outputs, include_thinking=False):\n",
        "    \"\"\"flattens a prompts x generations x content array to (prompts * generations) x content array\"\"\"\n",
        "    batch_size = len(bh)\n",
        "    bh_history = []\n",
        "    bh_wthinking = []\n",
        "    for i in range(batch_size):\n",
        "        _wo_thinking = deepcopy(bh[i])\n",
        "        _thinking = deepcopy(bh[i])\n",
        "        if num_gen > 1:  # 3d array\n",
        "            for j in range(num_gen):\n",
        "                if include_thinking:\n",
        "                    _thinking.append({\"role\": \"assistant\", \"content\": outputs[i][j]})\n",
        "\n",
        "                _wo_thinking.append({\"role\": \"assistant\", \"content\": outputs[i][j][1]})\n",
        "                bh_history.append(_wo_thinking)\n",
        "                bh_wthinking.append(_thinking)\n",
        "        else:  # 2d array\n",
        "            a = deepcopy(bh[i])\n",
        "            if include_thinking:\n",
        "                _thinking.append({\"role\": \"assistant\", \"content\": outputs[i]})\n",
        "\n",
        "            _wo_thinking.append({\"role\": \"assistant\", \"content\": outputs[i][1]})\n",
        "            bh_history.append(_wo_thinking)\n",
        "            bh_wthinking.append(_thinking)\n",
        "    return bh_history, bh_wthinking\n",
        "\n",
        "\n",
        "def res(generator, batch, max_new_tokens=1000, num_return_sequences=1):\n",
        "    outputs = generator.generate(batch, max_new_tokens=max_new_tokens, num_return_sequences=num_return_sequences)\n",
        "    gens_with_history, gens_w_thinking = create_batch(batch, num_return_sequences, outputs, include_thinking=True)\n",
        "    return outputs, gens_with_history, gens_w_thinking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class StepData:\n",
        "    \"\"\"Data for a single step in a rollout\"\"\"\n",
        "    step_num: int\n",
        "    prompt: str\n",
        "    thinking: str\n",
        "    content: str\n",
        "    history_wo_thinking: List[Dict[str, str]]\n",
        "    history_w_thinking: List[Dict[str, str]]\n",
        "    tokens: List[int] = field(default_factory=list)  # Token IDs for backprop\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class RolloutData:\n",
        "    \"\"\"Complete data for a single rollout\"\"\"\n",
        "    rollout_id: int\n",
        "    initial_prompt: str\n",
        "    steps: List[StepData] = field(default_factory=list)\n",
        "    is_complete: bool = False\n",
        "    terminated_early: bool = False\n",
        "    termination_step: int = -1\n",
        "    reward: float = 0.0\n",
        "    metadata: Dict[str, Any] = field(default_factory=dict)\n",
        "\n",
        "    def add_step(self, step_data: StepData):\n",
        "        self.steps.append(step_data)\n",
        "\n",
        "    def get_total_steps(self) -> int:\n",
        "        return len(self.steps)\n",
        "\n",
        "    def mark_complete(self, early: bool = False):\n",
        "        self.is_complete = True\n",
        "        self.terminated_early = early\n",
        "        self.termination_step = len(self.steps)\n",
        "\n",
        "    def set_reward(self, reward: float):\n",
        "        self.reward = reward\n",
        "\n",
        "    def to_dict(self):\n",
        "        return asdict(self)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RolloutManager:\n",
        "    \"\"\"Manages multiple parallel rollouts for multi-turn RL evaluation\"\"\"\n",
        "\n",
        "    def __init__(self, generator: LLMGenerator, n_rollouts: int, max_steps: int = 50):\n",
        "        self.generator = generator\n",
        "        self.n_rollouts = n_rollouts\n",
        "        self.max_steps = max_steps\n",
        "        self.rollouts: List[RolloutData] = []\n",
        "        self.active_rollout_indices: List[int] = []\n",
        "\n",
        "    def initialize_rollouts(self, initial_prompts: List[str]):\n",
        "        \"\"\"Initialize n rollouts with initial prompts\"\"\"\n",
        "        assert len(initial_prompts) == self.n_rollouts, \"Number of prompts must match n_rollouts\"\n",
        "\n",
        "        self.rollouts = [\n",
        "            RolloutData(\n",
        "                rollout_id=i,\n",
        "                initial_prompt=initial_prompts[i],\n",
        "                metadata={\"created_at\": datetime.now().isoformat()}\n",
        "            )\n",
        "            for i in range(self.n_rollouts)\n",
        "        ]\n",
        "        self.active_rollout_indices = list(range(self.n_rollouts))\n",
        "        print(f\"Initialized {self.n_rollouts} rollouts\")\n",
        "\n",
        "    def execute_step(self, step_num: int, prompts: List[str], max_new_tokens: int = 1000):\n",
        "        \"\"\"Execute a single step for all active rollouts\"\"\"\n",
        "        if not self.active_rollout_indices:\n",
        "            print(\"No active rollouts\")\n",
        "            return\n",
        "\n",
        "        # Get active rollouts\n",
        "        active_rollouts = [self.rollouts[i] for i in self.active_rollout_indices]\n",
        "\n",
        "        # Build histories for each active rollout\n",
        "        histories = []\n",
        "        for rollout in active_rollouts:\n",
        "            if len(rollout.steps) == 0:\n",
        "                # First step: empty history\n",
        "                histories.append([])\n",
        "            else:\n",
        "                # Use the last step's history without thinking\n",
        "                histories.append(rollout.steps[-1].history_wo_thinking)\n",
        "\n",
        "        # Create batch with new prompts\n",
        "        batch = []\n",
        "        for i, prompt in enumerate(prompts):\n",
        "            hist = deepcopy(histories[i])\n",
        "            hist.append({\"role\": \"user\", \"content\": prompt})\n",
        "            batch.append(hist)\n",
        "\n",
        "        # Generate outputs (num_return_sequences=1 as per requirement)\n",
        "        outputs, gens_with_history, gens_w_thinking = res(\n",
        "            self.generator,\n",
        "            batch,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            num_return_sequences=1\n",
        "        )\n",
        "\n",
        "        # Store step data for each active rollout\n",
        "        for i, rollout_idx in enumerate(self.active_rollout_indices):\n",
        "            thinking, content = outputs[i]  # outputs[i] is [thinking, content]\n",
        "\n",
        "            step_data = StepData(\n",
        "                step_num=step_num,\n",
        "                prompt=prompts[i],\n",
        "                thinking=thinking,\n",
        "                content=content,\n",
        "                history_wo_thinking=gens_with_history[i],\n",
        "                history_w_thinking=gens_w_thinking[i],\n",
        "                tokens=[]  # Will be populated if needed for backprop\n",
        "            )\n",
        "\n",
        "            self.rollouts[rollout_idx].add_step(step_data)\n",
        "\n",
        "        print(f\"Step {step_num} completed for {len(self.active_rollout_indices)} rollouts\")\n",
        "\n",
        "    def check_termination_conditions(self, termination_fn=None) -> List[int]:\n",
        "        \"\"\"Check which rollouts should terminate. Returns indices of rollouts to terminate.\"\"\"\n",
        "        to_terminate = []\n",
        "\n",
        "        for rollout_idx in self.active_rollout_indices:\n",
        "            rollout = self.rollouts[rollout_idx]\n",
        "\n",
        "            # Check max steps\n",
        "            if rollout.get_total_steps() >= self.max_steps:\n",
        "                to_terminate.append(rollout_idx)\n",
        "                rollout.mark_complete(early=False)\n",
        "                continue\n",
        "\n",
        "            # Custom termination function\n",
        "            if termination_fn and rollout.steps:\n",
        "                last_step = rollout.steps[-1]\n",
        "                if termination_fn(rollout, last_step):\n",
        "                    to_terminate.append(rollout_idx)\n",
        "                    rollout.mark_complete(early=True)\n",
        "\n",
        "        # Remove terminated rollouts from active list\n",
        "        for idx in to_terminate:\n",
        "            self.active_rollout_indices.remove(idx)\n",
        "\n",
        "        if to_terminate:\n",
        "            print(f\"Terminated {len(to_terminate)} rollouts. {len(self.active_rollout_indices)} still active\")\n",
        "\n",
        "        return to_terminate\n",
        "\n",
        "    def run_rollouts(self, prompt_generator_fn, termination_fn=None, max_new_tokens: int = 1000):\n",
        "        \"\"\"\n",
        "        Run all rollouts until completion.\n",
        "\n",
        "        Args:\n",
        "            prompt_generator_fn: Function that takes (rollout_data, step_num) and returns next prompt\n",
        "            termination_fn: Optional function that takes (rollout_data, step_data) and returns bool\n",
        "            max_new_tokens: Max tokens to generate per step\n",
        "        \"\"\"\n",
        "        step_num = 0\n",
        "\n",
        "        while self.active_rollout_indices and step_num < self.max_steps:\n",
        "            # Generate prompts for active rollouts\n",
        "            prompts = []\n",
        "            for rollout_idx in self.active_rollout_indices:\n",
        "                rollout = self.rollouts[rollout_idx]\n",
        "                prompt = prompt_generator_fn(rollout, step_num)\n",
        "                prompts.append(prompt)\n",
        "\n",
        "            # Execute step\n",
        "            self.execute_step(step_num, prompts, max_new_tokens)\n",
        "\n",
        "            # Check termination\n",
        "            self.check_termination_conditions(termination_fn)\n",
        "\n",
        "            step_num += 1\n",
        "\n",
        "        # Mark any remaining active rollouts as complete\n",
        "        for rollout_idx in self.active_rollout_indices:\n",
        "            self.rollouts[rollout_idx].mark_complete(early=False)\n",
        "\n",
        "        print(f\"\\nAll rollouts complete. Total steps: {step_num}\")\n",
        "\n",
        "    def assign_rewards(self, reward_fn):\n",
        "        \"\"\"Assign rewards to all rollouts using provided reward function\"\"\"\n",
        "        for rollout in self.rollouts:\n",
        "            reward = reward_fn(rollout)\n",
        "            rollout.set_reward(reward)\n",
        "        print(f\"Rewards assigned to {len(self.rollouts)} rollouts\")\n",
        "\n",
        "    def get_rollout_summary(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get summary statistics of all rollouts\"\"\"\n",
        "        total_steps = [r.get_total_steps() for r in self.rollouts]\n",
        "        early_terminations = sum(1 for r in self.rollouts if r.terminated_early)\n",
        "        rewards = [r.reward for r in self.rollouts]\n",
        "\n",
        "        return {\n",
        "            \"total_rollouts\": len(self.rollouts),\n",
        "            \"avg_steps\": sum(total_steps) / len(total_steps) if total_steps else 0,\n",
        "            \"min_steps\": min(total_steps) if total_steps else 0,\n",
        "            \"max_steps\": max(total_steps) if total_steps else 0,\n",
        "            \"early_terminations\": early_terminations,\n",
        "            \"avg_reward\": sum(rewards) / len(rewards) if rewards else 0,\n",
        "            \"step_distribution\": total_steps,\n",
        "            \"rewards\": rewards\n",
        "        }\n",
        "\n",
        "    def save_rollouts(self, filepath: str, format: str = \"pickle\"):\n",
        "        \"\"\"Save all rollout data to file\"\"\"\n",
        "        if format == \"pickle\":\n",
        "            with open(filepath, \"wb\") as f:\n",
        "                pickle.dump(self.rollouts, f)\n",
        "        elif format == \"json\":\n",
        "            with open(filepath, \"w\") as f:\n",
        "                data = [r.to_dict() for r in self.rollouts]\n",
        "                json.dump(data, f, indent=2)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown format: {format}\")\n",
        "\n",
        "        print(f\"Saved {len(self.rollouts)} rollouts to {filepath}\")\n",
        "\n",
        "    @staticmethod\n",
        "    def load_rollouts(filepath: str, format: str = \"pickle\") -> List[RolloutData]:\n",
        "        \"\"\"Load rollout data from file\"\"\"\n",
        "        if format == \"pickle\":\n",
        "            with open(filepath, \"rb\") as f:\n",
        "                return pickle.load(f)\n",
        "        elif format == \"json\":\n",
        "            with open(filepath, \"r\") as f:\n",
        "                data = json.load(f)\n",
        "                # Would need to reconstruct RolloutData objects from dicts\n",
        "                return data\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown format: {format}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dummy_reward_function(rollout: RolloutData) -> float:\n",
        "    \"\"\"\n",
        "    Dummy reward function - replace with actual task-specific logic.\n",
        "    \n",
        "    Examples:\n",
        "    - Check if final output matches expected answer\n",
        "    - Count number of correct steps\n",
        "    - Measure similarity to reference solution\n",
        "    \"\"\"\n",
        "    # Example: reward based on number of steps completed\n",
        "    num_steps = rollout.get_total_steps()\n",
        "    \n",
        "    # Higher reward for completing more steps (up to max)\n",
        "    if rollout.terminated_early:\n",
        "        # Penalty for early termination\n",
        "        return num_steps * 0.5\n",
        "    else:\n",
        "        # Bonus for completing full rollout\n",
        "        return num_steps * 1.0 + 10.0\n",
        "\n",
        "\n",
        "def dummy_termination_check(rollout: RolloutData, last_step: StepData) -> bool:\n",
        "    \"\"\"\n",
        "    Dummy termination check - replace with actual task-specific logic.\n",
        "    \n",
        "    Examples:\n",
        "    - Check if output contains stop phrase (\"DONE\", \"FINAL ANSWER:\", etc.)\n",
        "    - Check if task objective is met\n",
        "    - Check for errors or invalid states\n",
        "    \"\"\"\n",
        "    # Example: terminate if content contains \"DONE\"\n",
        "    if \"DONE\" in last_step.content.upper():\n",
        "        return True\n",
        "    \n",
        "    # Example: random early termination (10% chance) to simulate giving up\n",
        "    import random\n",
        "    if random.random() < 0.1:\n",
        "        return True\n",
        "    \n",
        "    return False\n",
        "\n",
        "\n",
        "def dummy_prompt_generator(rollout: RolloutData, step_num: int) -> str:\n",
        "    \"\"\"\n",
        "    Dummy prompt generator - replace with actual task-specific logic.\n",
        "    \n",
        "    Examples:\n",
        "    - For math: generate next problem in sequence\n",
        "    - For coding: provide next test case or requirement\n",
        "    - For reasoning: ask follow-up questions\n",
        "    \"\"\"\n",
        "    if step_num == 0:\n",
        "        # First step uses initial prompt\n",
        "        return rollout.initial_prompt\n",
        "    else:\n",
        "        # Subsequent steps: simple continuation\n",
        "        return f\"Continue with step {step_num + 1}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example usage\n",
        "\n",
        "# Initialize generator\n",
        "generator = LLMGenerator(\"Qwen/Qwen3-0.6B\")\n",
        "\n",
        "# Setup rollouts\n",
        "n_rollouts = 4\n",
        "max_steps = 50\n",
        "\n",
        "# Create initial prompts for each rollout\n",
        "initial_prompts = [\n",
        "    \"Solve this problem step by step: What is 15 + 27?\",\n",
        "    \"Write a story about a robot learning to cook.\",\n",
        "    \"Explain how photosynthesis works.\",\n",
        "    \"Debug this code: for i in range(10) print(i)\"\n",
        "]\n",
        "\n",
        "# Create manager\n",
        "manager = RolloutManager(generator, n_rollouts=n_rollouts, max_steps=max_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize rollouts\n",
        "manager.initialize_rollouts(initial_prompts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run all rollouts to completion\n",
        "manager.run_rollouts(\n",
        "    prompt_generator_fn=dummy_prompt_generator,\n",
        "    termination_fn=dummy_termination_check,\n",
        "    max_new_tokens=512\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assign rewards\n",
        "manager.assign_rewards(dummy_reward_function)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get summary\n",
        "summary = manager.get_rollout_summary()\n",
        "print(\"\\n=== Rollout Summary ===\")\n",
        "for key, value in summary.items():\n",
        "    print(f\"{key}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save rollouts for later analysis/backprop\n",
        "manager.save_rollouts(\"rollout_data.pkl\", format=\"pickle\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inspect individual rollout\n",
        "rollout = manager.rollouts[0]\n",
        "print(f\"\\n=== Rollout {rollout.rollout_id} ===\")\n",
        "print(f\"Initial prompt: {rollout.initial_prompt}\")\n",
        "print(f\"Total steps: {rollout.get_total_steps()}\")\n",
        "print(f\"Terminated early: {rollout.terminated_early}\")\n",
        "print(f\"Reward: {rollout.reward}\")\n",
        "print(f\"\\nSteps:\")\n",
        "for step in rollout.steps:\n",
        "    print(f\"  Step {step.step_num}: {step.prompt[:50]}... -> {step.content[:50]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Access full step data for backprop\n",
        "# Each step contains:\n",
        "# - step.prompt: the input prompt\n",
        "# - step.thinking: the thinking process\n",
        "# - step.content: the actual response\n",
        "# - step.history_wo_thinking: conversation history without thinking\n",
        "# - step.history_w_thinking: conversation history with thinking\n",
        "# - step.tokens: token IDs (can be populated during generation if needed)\n",
        "\n",
        "# Example: get all responses for backprop\n",
        "for rollout in manager.rollouts:\n",
        "    print(f\"\\nRollout {rollout.rollout_id} - Reward: {rollout.reward}\")\n",
        "    for step in rollout.steps:\n",
        "        # Here you would:\n",
        "        # 1. Re-tokenize or use stored tokens\n",
        "        # 2. Compute loss with reward signal\n",
        "        # 3. Backprop gradients\n",
        "        print(f\"  Step {step.step_num}: content length = {len(step.content)} chars\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
